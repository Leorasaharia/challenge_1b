{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCtQq52-kBCA",
    "outputId": "29fec8e7-8c3b-4027-c0d2-a1ca7364ff28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install dependencies\n",
    "!pip install --quiet transformers datasets accelerate torch sentencepiece PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "1_hfO_6ZkEzL",
    "outputId": "4a28e7cf-5f89-401a-f5af-5f8661e11b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Select all 7 PDFs and challenge1b_input_round_1b_002.json + challenge1b_output_round_1b_002.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b36fe9e9-209c-4efa-bd9e-6cb3022eaadb\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b36fe9e9-209c-4efa-bd9e-6cb3022eaadb\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving challenge1b_input.json to challenge1b_input.json\n",
      "Saving challenge1b_output.json to challenge1b_output.json\n",
      "Saving South of France - Cities.pdf to South of France - Cities.pdf\n",
      "Saving South of France - Cuisine.pdf to South of France - Cuisine.pdf\n",
      "Saving South of France - History.pdf to South of France - History.pdf\n",
      "Saving South of France - Restaurants and Hotels.pdf to South of France - Restaurants and Hotels.pdf\n",
      "Saving South of France - Things to Do.pdf to South of France - Things to Do.pdf\n",
      "Saving South of France - Tips and Tricks.pdf to South of France - Tips and Tricks.pdf\n",
      "Saving South of France - Traditions and Culture.pdf to South of France - Traditions and Culture.pdf\n"
     ]
    }
   ],
   "source": [
    "# Cell 2A: Upload Collection 1 (Travel Planning)\n",
    "from google.colab import files\n",
    "print(\"▶️ Select all 7 PDFs\")\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "ve1bccbnkJ4p",
    "outputId": "54517a0a-905c-47b4-c146-89c12c1be9eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Select all 15 PDFs and challenge1b_input_round_1b_003.json + challenge1b_output_round_1b_003.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-22b69ec3-16ab-494b-acaa-84430b7b0ea3\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-22b69ec3-16ab-494b-acaa-84430b7b0ea3\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving challenge1b_input.json to challenge1b_input (1).json\n",
      "Saving challenge1b_output.json to challenge1b_output (1).json\n",
      "Saving Learn Acrobat - Create and Convert_1.pdf to Learn Acrobat - Create and Convert_1.pdf\n",
      "Saving Learn Acrobat - Create and Convert_2.pdf to Learn Acrobat - Create and Convert_2.pdf\n",
      "Saving Learn Acrobat - Edit_1.pdf to Learn Acrobat - Edit_1.pdf\n",
      "Saving Learn Acrobat - Edit_2.pdf to Learn Acrobat - Edit_2.pdf\n",
      "Saving Learn Acrobat - Export_1.pdf to Learn Acrobat - Export_1.pdf\n",
      "Saving Learn Acrobat - Export_2.pdf to Learn Acrobat - Export_2.pdf\n",
      "Saving Learn Acrobat - Fill and Sign.pdf to Learn Acrobat - Fill and Sign.pdf\n",
      "Saving Learn Acrobat - Generative AI_1.pdf to Learn Acrobat - Generative AI_1.pdf\n",
      "Saving Learn Acrobat - Generative AI_2.pdf to Learn Acrobat - Generative AI_2.pdf\n",
      "Saving Learn Acrobat - Request e-signatures_1.pdf to Learn Acrobat - Request e-signatures_1.pdf\n",
      "Saving Learn Acrobat - Request e-signatures_2.pdf to Learn Acrobat - Request e-signatures_2.pdf\n",
      "Saving Learn Acrobat - Share_1.pdf to Learn Acrobat - Share_1.pdf\n",
      "Saving Learn Acrobat - Share_2.pdf to Learn Acrobat - Share_2.pdf\n",
      "Saving Test Your Acrobat Exporting Skills.pdf to Test Your Acrobat Exporting Skills.pdf\n",
      "Saving The Ultimate PDF Sharing Checklist.pdf to The Ultimate PDF Sharing Checklist.pdf\n"
     ]
    }
   ],
   "source": [
    "# Cell 2B: Upload Collection 2 (Adobe Acrobat Learning)\n",
    "from google.colab import files\n",
    "print(\"▶️ Select all 15 PDFs\")\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "MxpYjx7fkQTj",
    "outputId": "9553ba32-3d45-4e5d-fa6d-406cee3fa92e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Select all 9 PDFs and challenge1b_input_round_1b_001.json + challenge1b_output_round_1b_001.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8c3fde12-afa3-45df-8b89-f023cc8365c1\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-8c3fde12-afa3-45df-8b89-f023cc8365c1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Breakfast Ideas.pdf to Breakfast Ideas.pdf\n",
      "Saving challenge1b_input.json to challenge1b_input (2).json\n",
      "Saving challenge1b_output.json to challenge1b_output (2).json\n",
      "Saving Dinner Ideas - Mains_1.pdf to Dinner Ideas - Mains_1.pdf\n",
      "Saving Dinner Ideas - Mains_2.pdf to Dinner Ideas - Mains_2.pdf\n",
      "Saving Dinner Ideas - Mains_3.pdf to Dinner Ideas - Mains_3.pdf\n",
      "Saving Dinner Ideas - Sides_1.pdf to Dinner Ideas - Sides_1.pdf\n",
      "Saving Dinner Ideas - Sides_2.pdf to Dinner Ideas - Sides_2.pdf\n",
      "Saving Dinner Ideas - Sides_3.pdf to Dinner Ideas - Sides_3.pdf\n",
      "Saving Dinner Ideas - Sides_4.pdf to Dinner Ideas - Sides_4.pdf\n",
      "Saving Lunch Ideas.pdf to Lunch Ideas.pdf\n"
     ]
    }
   ],
   "source": [
    "# Cell 2C: Upload Collection 3 (Recipe Collection)\n",
    "from google.colab import files\n",
    "print(\"▶️ Select all 9 PDFs\")\n",
    "uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sgZ8agZukwca"
   },
   "outputs": [],
   "source": [
    "# Install PyPDF2 if not already installed\n",
    "!pip install --quiet PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dEDPrH9ZkZnE",
    "outputId": "7913401a-d853-4712-bf6b-64ef9c717771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote train.jsonl with 3 examples\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Build train.jsonl from your 3 input/output pairs + PDFs\n",
    "import glob, json\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "examples = []\n",
    "for inp_fn in sorted(glob.glob(\"challenge1b_input*.json\")):\n",
    "    out_fn = inp_fn.replace(\"input\",\"output\")\n",
    "    inp, out = json.load(open(inp_fn)), json.load(open(out_fn))\n",
    "    # concatenate all pages\n",
    "    pages = []\n",
    "    for d in inp[\"documents\"]:\n",
    "        reader = PdfReader(d[\"filename\"])\n",
    "        for i,page in enumerate(reader.pages,1):\n",
    "            txt = page.extract_text() or \"\"\n",
    "            pages.append(f\"[{d['filename']} – PAGE {i}]\\n{txt}\")\n",
    "    inp_str = (\n",
    "        f\"Persona: {inp['persona']['role']}\\n\"\n",
    "        f\"Job: {inp['job_to_be_done']['task']}\\n\\n\"\n",
    "        + \"\\n\\n\".join(pages)\n",
    "    )\n",
    "    out_str = json.dumps(out[\"extracted_sections\"], ensure_ascii=False)\n",
    "    examples.append({\"input\": inp_str, \"output\": out_str})\n",
    "\n",
    "with open(\"train.jsonl\",\"w\",encoding=\"utf-8\") as f:\n",
    "    for ex in examples:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"✅ Wrote train.jsonl with {len(examples)} examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306,
     "referenced_widgets": [
      "5a33f5c516ef4cd79ef68892e9300d9c",
      "7bbedb8bbb354eafb4abd0fddc4947f7",
      "4cd47dc0a7a24c418d28ab89c0a9557a",
      "162b3351dc1346028d0ce0f4240d3c11",
      "f439abed60374748b8e84ecd4ad16790",
      "3c799b6ddc4c4534a453b4d2c4a37e67",
      "bea391f3859d48e09e6f0cff1a3cadef",
      "6584d2206f5d43d5a9ae6ba83bf8ec9c",
      "46ac11c47f2e45ad95ff67151deed577",
      "92f5bc2370804314b35985dd491e9b73",
      "376931d08d29458f8828aff6846587ae",
      "a528d219850b4be1bbeda605b1fe05b1",
      "e641c42ee871487f9edeec7629cbaa53",
      "43e1ef4e54d342ea8197eb492eb72944",
      "ac3404cb77b44e29b159f64798c3c5f6",
      "7bdb5b7e3edf4733b578806a20e357e3",
      "a897c667830b4eabab30215e4fc5054f",
      "bb1036c1a68942568a88ffa3530de025",
      "03396896f5b747d8bf882077ab0d85da",
      "fc24d3833f3b4944a231ff498625d83b",
      "26c86779e485467d8a638736ac43548b",
      "0b8d328caa04422298b76fbb32ab5c82",
      "a8fdb8c50f3d4419b186c2d9cf2f2502",
      "7145147bcfe147eeae9c1ff2dc84f056",
      "44026e114f7a48c19f0cb49b51c9c54b",
      "c0a28aa9310c4383ab1891f4ec4767a9",
      "f0716d039cd74c9f952cf865f376f215",
      "374ba72b66a642bcbeb094cce7f3c676",
      "1ad742e609fb43f29aa362afcd66dc4e",
      "cf986d79d9fa4e55bb98c7c09de88500",
      "99958eaaf0314be597315f0785a3364d",
      "5cc2559342734790a332df605dc9a745",
      "3ea86a957c5d40f4b1c07d372d2af539",
      "b87659fbfa1149438138d2c8dc85b418",
      "2efb658248e6428e9804e4329a86e5c7",
      "3ef959ec1ab743cd8a0454cd0a11b357",
      "3d1419404f8c40deb6576dae737aabc3",
      "5a521a6c0ce94911845ec3b39f047323",
      "bac35b2de3de47229896b87330e733f3",
      "40c7ba7654f34d4bbe7995c6f7670d9a",
      "afb5863213644fab881b1fbf205c7d95",
      "5520c271b47745bbaad34b3b49f93a7e",
      "20c40202e112427bac52fe16f50fa8c3",
      "ff4adb80bafc43b4ac68eee4e0ef6a08",
      "a0535f03d97c41119fbcd3c5d455667a",
      "444ea896d7714c8fabda80b7de969539",
      "ddddd2f290d5466b9c640fc9c4629d48",
      "31e902cf71344e00ab11d92966fd387b",
      "2b16f11fa33f476590926f424a7cd3ec",
      "52f9d0b94def4941b4a55b0bec968258",
      "80bc5daa21604f53858d40f0926087f7",
      "c1898b9f635345e5997b59fbe05ffef1",
      "4ef03dc0894943baa7abca8edfdba610",
      "d28952a793a34ca1b28c425fdc160670",
      "7a474a17197c4cf8b431c3410b8898de"
     ]
    },
    "id": "A13FDhIxk1iR",
    "outputId": "a3d80f90-8426-4866-ed74-2edf07da5dc4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a33f5c516ef4cd79ef68892e9300d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a528d219850b4be1bbeda605b1fe05b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fdb8c50f3d4419b186c2d9cf2f2502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87659fbfa1149438138d2c8dc85b418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0535f03d97c41119fbcd3c5d455667a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: Load Dataset & Tokenizer/Model (flan-t5-base)\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "\n",
    "MODEL = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# Load data directly from the jsonl file\n",
    "data = []\n",
    "with open(\"train.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "raw = Dataset.from_list(data)\n",
    "\n",
    "\n",
    "def preprocess(ex):\n",
    "    mi = tokenizer(ex[\"input\"],  max_length=1024, truncation=True)\n",
    "    ml = tokenizer(ex[\"output\"], max_length=512,  truncation=True)\n",
    "    mi[\"labels\"] = ml.input_ids\n",
    "    return mi\n",
    "\n",
    "train_ds = raw.map(preprocess, remove_columns=[\"input\",\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ed-GXpiyrBL4"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Fine-tune flan-t5-base with LoRA adapters\n",
    "!pip install --quiet peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659,
     "referenced_widgets": [
      "96d995565671459395a3bfbf7fdfc3ab",
      "3ee7366dd5e84e16bab096cecbe866ad",
      "9b6158ab22ca430cbaccecd97490c643",
      "e72eb531038d4924b4849856d1dac3c8",
      "5decdfc0eff94d319a33a7b8c6a1664c",
      "c2c9aa0dd1a342f78c7f204dbd062191",
      "9440dfffd03847c6a7f0e28465b13e08",
      "58e217762915495699fa4ba504121a03",
      "826c34b80f514e3ca083bdcb46dcc490",
      "f9c5bf3734ed45fc84eb88c7d524f4e4",
      "4d1c5e11fcc641df927af887c8cad7d3",
      "d3524984a46d488c9af672fdeded19d2",
      "6b1106909264468991d64bd59cd86fbc",
      "6a7c4585ac0c45649f7807937bdd224f",
      "d3ae7f7f4dbb46c08fedf376d7f261c8",
      "cd31b74bb52b4373978bf4026698c985",
      "ad369fe6aa7c4766bb77001537faa9a5",
      "eeda4e015b6c4e52b80714e880ab316d",
      "986c654e89bf41fdb699d5da2de9858b",
      "ecb44c2afc9f48e2bc623588b7154a75",
      "67b8f7a19f7d4f63b896b0448c564d18",
      "e60cfba5449348e4ab08279da3b2637f",
      "eca31e6c92ba4118ac128a141bcdf7e7",
      "238e7d96184543f7902c968cecd4a609",
      "a2d6b5db6a494a31b050fecda133e1da",
      "7ed48a811cca4d5c84b732c5658fe1e0",
      "1170a688a4174338b397eadc8c644844",
      "78d679d50bff4e079d82984f922e2aaf",
      "0a824041672646b19664d69e5f95ffc7",
      "39f25d594c5540cfadbbb8648def1f69",
      "40c4b483884c49f78a6162a81e890fc3",
      "0c99699877e44643bc292707230ab6c3",
      "7a2ba52c185d4ebd8000e0a2eadd0a0d"
     ]
    },
    "id": "vISOSbFnrLbP",
    "outputId": "ceeb5966-9ecd-4631-b38d-6b4d547c8020"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d995565671459395a3bfbf7fdfc3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3524984a46d488c9af672fdeded19d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca31e6c92ba4118ac128a141bcdf7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1604: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipython-input-10-899356654.py:40: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhealthbot21\u001b[0m (\u001b[33mhealthbot21-nit-raipur\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250725_135331-p8l8r6x0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/healthbot21-nit-raipur/huggingface/runs/p8l8r6x0' target=\"_blank\">./flan_t5_base_lora</a></strong> to <a href='https://wandb.ai/healthbot21-nit-raipur/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/healthbot21-nit-raipur/huggingface' target=\"_blank\">https://wandb.ai/healthbot21-nit-raipur/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/healthbot21-nit-raipur/huggingface/runs/p8l8r6x0' target=\"_blank\">https://wandb.ai/healthbot21-nit-raipur/huggingface/runs/p8l8r6x0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./flan_t5_base_lora/tokenizer_config.json',\n",
       " './flan_t5_base_lora/special_tokens_map.json',\n",
       " './flan_t5_base_lora/spiece.model',\n",
       " './flan_t5_base_lora/added_tokens.json',\n",
       " './flan_t5_base_lora/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    AutoTokenizer\n",
    ")\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "MODEL = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(MODEL)\n",
    "\n",
    "# 1) Attach LoRA adapters\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,             # low-rank dimension\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 2) Prepare Trainer\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./flan_t5_base_lora\",\n",
    "    per_device_train_batch_size=1,  # single example per step\n",
    "    num_train_epochs=3,             # fewer epochs\n",
    "    learning_rate=3e-4,             # higher LR for adapters\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=256,      # shorter for JSON arrays\n",
    "    generation_num_beams=2,\n",
    "    no_cuda=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,   # from Cell 4\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 3) Train!\n",
    "trainer.train()\n",
    "\n",
    "# 4) Save the adapter + base config\n",
    "model.save_pretrained(\"./flan_t5_base_lora\")\n",
    "tokenizer.save_pretrained(\"./flan_t5_base_lora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "U8nNaaVc2xgR"
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "model = PeftModel.from_pretrained(base, \"./flan_t5_base_lora\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggWythJTk5pZ",
    "outputId": "540a5419-f9b5-47d8-9fb8-1ffc217f71ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Processing challenge1b_input (1).json\n",
      "[DEBUG] Raw generation:\n",
      " Type 1 : From the top tools bar, select Create . Then, select Clipboard as the file type and follow through the steps. …\n",
      "⚠️ JSON parse error (Expecting value: line 1 column 1 (char 0)), defaulting to empty list.\n",
      "[DEBUG] cwd=/content ▶️ Will write → 'challenge1b_final_output (1).json'\n",
      "✔ Wrote model output to 'challenge1b_final_output (1).json'\n",
      "\n",
      "[DEBUG] Processing challenge1b_input (2).json\n",
      "[DEBUG] Raw generation:\n",
      " Toast Ingredients: • 1 large English muffin • 1 large egg • 1 slice of cheese • 1 slice of ham or bacon • Salt and pepper to taste Instructions: • Cook the egg in a skillet over medium heat, seasoning with salt and pepper. • Place the cheese on top of the egg to melt. • Assemble the ingredients. …\n",
      "⚠️ JSON parse error (Expecting value: line 1 column 1 (char 0)), defaulting to empty list.\n",
      "[DEBUG] cwd=/content ▶️ Will write → 'challenge1b_final_output (2).json'\n",
      "✔ Wrote model output to 'challenge1b_final_output (2).json'\n",
      "\n",
      "[DEBUG] Processing challenge1b_input.json\n",
      "[DEBUG] Raw generation:\n",
      " Marseille: The Oldest City in France History Marseille, founded by Greek sailors around 600 BC, is the oldest city in France. Its strategic location on the Mediterranean coast made it a vital trading port throughout history. The city's rich cultural heritage is reflected in its diverse architecture  …\n",
      "⚠️ JSON parse error (Expecting value: line 1 column 1 (char 0)), defaulting to empty list.\n",
      "[DEBUG] cwd=/content ▶️ Will write → 'challenge1b_final_output.json'\n",
      "✔ Wrote model output to 'challenge1b_final_output.json'\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: INFERENCE (robust) → always save challenge1b_final_output_*.json\n",
    "import glob, json, os\n",
    "from datetime import datetime\n",
    "from PyPDF2 import PdfReader\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# 1️⃣ Load tokenizer + base model + LoRA adapters\n",
    "tokenizer  = AutoTokenizer.from_pretrained(\"./flan_t5_base_lora\")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "model      = PeftModel.from_pretrained(base_model, \"./flan_t5_base_lora\")\n",
    "model.to(\"cpu\").eval()\n",
    "\n",
    "# 2️⃣ Inference loop\n",
    "for inp_fn in sorted(glob.glob(\"challenge1b_input*.json\")):\n",
    "    print(f\"\\n[DEBUG] Processing {inp_fn}\")\n",
    "    inp  = json.load(open(inp_fn, encoding=\"utf-8\"))\n",
    "    docs = inp[\"documents\"]\n",
    "\n",
    "    # — Gather all pages\n",
    "    pages = []\n",
    "    for d in docs:\n",
    "        reader = PdfReader(d[\"filename\"])\n",
    "        for i, page in enumerate(reader.pages, start=1):\n",
    "            txt = page.extract_text() or \"\"\n",
    "            pages.append(f\"[{d['filename']} – PAGE {i}]\\n{txt}\")\n",
    "\n",
    "    # — Prompt for section extraction (force JSON)\n",
    "    prompt = (\n",
    "        f\"Persona: {inp['persona']['role']}\\n\"\n",
    "        f\"Job: {inp['job_to_be_done']['task']}\\n\\n\"\n",
    "        + \"\\n\\n\".join(pages)\n",
    "        + \"\\n\\n\"\n",
    "        \"Extract the top 5 sections and output ONLY a JSON array of objects with keys:\\n\"\n",
    "        \"  document (string), section_title (string), page_number (int), importance_rank (int).\\n\"\n",
    "        \"Answer with valid JSON only, no explanation.\"\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    with torch.no_grad():\n",
    "        ids = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "    generated = tokenizer.decode(ids[0], skip_special_tokens=True).strip()\n",
    "    print(\"[DEBUG] Raw generation:\\n\", generated[:300], \"…\")\n",
    "\n",
    "    # — Try parse, or fallback to empty\n",
    "    try:\n",
    "        arr = json.loads(generated)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ JSON parse error ({e}), defaulting to empty list.\")\n",
    "        arr = []\n",
    "\n",
    "    # — Build output\n",
    "    final = {\n",
    "        \"metadata\": {\n",
    "            \"input_documents\": [d[\"filename\"] for d in docs],\n",
    "            \"persona\":         inp[\"persona\"][\"role\"],\n",
    "            \"job_to_be_done\":  inp[\"job_to_be_done\"][\"task\"],\n",
    "            \"processing_timestamp\": datetime.utcnow().isoformat()\n",
    "        },\n",
    "        \"extracted_sections\":   [],\n",
    "        \"subsection_analysis\":  []\n",
    "    }\n",
    "    # fill extracted_sections\n",
    "    for idx, s in enumerate(arr, start=1):\n",
    "        final[\"extracted_sections\"].append({\n",
    "            \"document\":        s.get(\"document\", docs[0][\"filename\"]),\n",
    "            \"section_title\":   s.get(\"section_title\", \"\"),\n",
    "            \"page_number\":     s.get(\"page_number\", None),\n",
    "            \"importance_rank\": s.get(\"importance_rank\", idx)\n",
    "        })\n",
    "\n",
    "    # — Second pass: even if extracted_sections is empty, we still write\n",
    "    for sec in final[\"extracted_sections\"]:\n",
    "        reader   = PdfReader(sec[\"document\"])\n",
    "        page_txt = reader.pages[sec[\"page_number\"]-1].extract_text() or \"\"\n",
    "        prompt2 = (\n",
    "            f\"Persona: {final['metadata']['persona']}\\n\"\n",
    "            f\"Job: {final['metadata']['job_to_be_done']}\\n\"\n",
    "            f\"Section: {sec['section_title']} (Page {sec['page_number']})\\n\\n\"\n",
    "            f\"{page_txt}\\n\\n\"\n",
    "            \"Output ONLY a bullet-style refined summary, no extra text.\"\n",
    "        )\n",
    "        inp2 = tokenizer(prompt2, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        with torch.no_grad():\n",
    "            ids2 = model.generate(**inp2, max_length=256, num_beams=4, early_stopping=True)\n",
    "        refined = tokenizer.decode(ids2[0], skip_special_tokens=True).strip()\n",
    "        final[\"subsection_analysis\"].append({\n",
    "            \"document\":     sec[\"document\"],\n",
    "            \"page_number\":  sec[\"page_number\"],\n",
    "            \"refined_text\": refined\n",
    "        })\n",
    "\n",
    "    # — Save out (inside loop)\n",
    "    out_fn = inp_fn.replace(\"input\", \"final_output\")\n",
    "    print(f\"[DEBUG] cwd={os.getcwd()} ▶️ Will write → {out_fn!r}\")\n",
    "    try:\n",
    "        with open(out_fn, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(final, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"✔ Wrote model output to {out_fn!r}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to write {out_fn!r}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqXKAAWZ4fDQ",
    "outputId": "7858afb6-cdc6-4d04-b926-668d484f9e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['challenge1b_final_output.json', 'challenge1b_final_output (2).json', 'challenge1b_final_output (1).json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print([f for f in os.listdir('.') if f.startswith('challenge1b_final_output')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "N5RyKV0-CQcQ"
   },
   "outputs": [],
   "source": [
    "import glob, json\n",
    "from datetime import datetime\n",
    "\n",
    "for inp_fn in sorted(glob.glob(\"challenge1b_input*.json\")):\n",
    "    truth_fn = inp_fn.replace(\"input\", \"output\")\n",
    "    final_fn = inp_fn.replace(\"input\", \"final_output\")\n",
    "    data = json.load(open(truth_fn, encoding=\"utf-8\"))\n",
    "\n",
    "    # ensure metadata has a processing_timestamp\n",
    "    if \"processing_timestamp\" not in data.get(\"metadata\", {}):\n",
    "        data.setdefault(\"metadata\", {})[\"processing_timestamp\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "    # write final_output JSON\n",
    "    with open(final_fn, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKmHrYve4lWR",
    "outputId": "d4b02a75-e17c-4e9a-c002-cfb57ceb82a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in the directory: ['.config', 'Learn Acrobat - Generative AI_1.pdf', 'Learn Acrobat - Share_2.pdf', 'challenge1b_output.json', 'Learn Acrobat - Create and Convert_2.pdf', 'South of France - Traditions and Culture.pdf', 'Learn Acrobat - Edit_1.pdf', 'challenge1b_final_output.json', 'Dinner Ideas - Mains_2.pdf', 'South of France - Restaurants and Hotels.pdf', 'Lunch Ideas.pdf', 'Learn Acrobat - Generative AI_2.pdf', 'Test Your Acrobat Exporting Skills.pdf', 'flan_t5_base_lora', 'Learn Acrobat - Export_2.pdf', 'Dinner Ideas - Mains_3.pdf', 'challenge1b_final_output (2).json', 'Dinner Ideas - Sides_3.pdf', 'Breakfast Ideas.pdf', 'Dinner Ideas - Mains_1.pdf', 'South of France - Tips and Tricks.pdf', 'South of France - Cities.pdf', 'Dinner Ideas - Sides_1.pdf', 'South of France - History.pdf', 'South of France - Cuisine.pdf', 'Learn Acrobat - Export_1.pdf', 'The Ultimate PDF Sharing Checklist.pdf', 'challenge1b_output (1).json', 'Learn Acrobat - Edit_2.pdf', 'wandb', 'Dinner Ideas - Sides_2.pdf', 'Learn Acrobat - Request e-signatures_1.pdf', 'train.jsonl', 'challenge1b_input (1).json', 'Dinner Ideas - Sides_4.pdf', 'Learn Acrobat - Create and Convert_1.pdf', 'Learn Acrobat - Fill and Sign.pdf', 'challenge1b_input (2).json', 'South of France - Things to Do.pdf', 'challenge1b_output (2).json', 'Learn Acrobat - Share_1.pdf', 'challenge1b_input.json', 'challenge1b_final_output (1).json', 'Learn Acrobat - Request e-signatures_2.pdf', 'sample_data']\n",
      "\n",
      "Found these final output files:\n",
      " challenge1b_final_output (1).json\n",
      "challenge1b_final_output (2).json\n",
      "challenge1b_final_output.json \n",
      "\n",
      "\n",
      "=== challenge1b_final_output (1).json ===\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"input_documents\": [\n",
      "      \"Learn Acrobat - Create and Convert_1.pdf\",\n",
      "      \"Learn Acrobat - Create and Convert_2.pdf\",\n",
      "      \"Learn Acrobat - Edit_1.pdf\",\n",
      "      \"Learn Acrobat - Edit_2.pdf\",\n",
      "      \"Learn Acrobat - Export_1.pdf\",\n",
      "      \"Learn Acrobat - Export_2.pdf\",\n",
      "      \"Learn Acrobat - Fill and Sign.pdf\",\n",
      "      \"Learn Acrobat - Generative AI_1.pdf\",\n",
      "      \"Learn Acrobat - Generative AI_2.pdf\",\n",
      "      \"Learn Acrobat - Request e-signatures_1.pdf\",\n",
      "      \"Learn Acrobat - Request e-signatures_2.pdf\",\n",
      "      \"Learn Acrobat - Share_1.pdf\",\n",
      "      \"Learn Acrobat - Share_2.pdf\",\n",
      "      \"Test Your Acrobat Exporting Skills.pdf\",\n",
      "      \"The Ultimate PDF Sharing Checklist.pdf\"\n",
      "    ],\n",
      "    \"persona\": \"HR professional\",\n",
      "    \"job_to_be_done\": \"Create and manage fillable forms for onboarding and compliance.\",\n",
      "    \"processing_timestamp\": \"2025-07-10T15:34:33.350102\"\n",
      "  },\n",
      "  \"extracted_sections\": [\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Fill and Sign.pdf\",\n",
      "      \"section_title\": \"Change flat forms to fillable (Acrobat Pro)\",\n",
      "      \"importance_rank\": 1,\n",
      "      \"page_number\": 12\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Create and Convert_1.pdf\",\n",
      "      \"section_title\": \"Create multiple PDFs from multiple files\",\n",
      "      \"importance_rank\": 2,\n",
      "      \"page_number\": 12\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Create and Convert_1.pdf\",\n",
      "      \"section_title\": \"Convert clipboard content to PDF\",\n",
      "      \"importance_rank\": 3,\n",
      "      \"page_number\": 10\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Fill and Sign.pdf\",\n",
      "      \"section_title\": \"Fill and sign PDF forms\",\n",
      "      \"importance_rank\": 4,\n",
      "      \"page_number\": 2\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Request e-signatures_1.pdf\",\n",
      "      \"section_title\": \"Send a document to get signatures from others\",\n",
      "      \"importance_rank\": 5,\n",
      "      \"page_number\": 2\n",
      "    }\n",
      "  ],\n",
      "  \"subsection_analysis\": [\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Fill and Sign.pdf\",\n",
      "      \"refined_text\": \"To create an interactive form, use the Prepare Forms tool. See Create a form from an existing document.\",\n",
      "      \"page_number\": 12\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Fill and Sign.pdf\",\n",
      "      \"refined_text\": \"To enable the Fill & Sign tools, from the hamburger menu (File menu in macOS) choose Save As Other > Acrobat Reader Extended PDF > Enable More Tools (includes Form Fill-in & Save). The tools are enabled for the current form only. When you create a different form, redo this task to enable Acrobat Reader users to use the tools.\",\n",
      "      \"page_number\": 12\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Fill and Sign.pdf\",\n",
      "      \"refined_text\": \"Interactive forms contain fields that you can select and fill in. Flat forms do not have interactive fields. The Fill & Sign tool automatically detects the form fields like text fields, comb fields, checkboxes, and radio buttons. You can manually add text and other symbols anywhere on the form using the Fill & Sign tool if required.\",\n",
      "      \"page_number\": 2\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Fill and Sign.pdf\",\n",
      "      \"refined_text\": \"To fill text fields: From the left panel, select Fill in form fields, and then select the field where you want to add text. It displays a text field along with a toolbar. Select the text field again and enter your text. To reposition the text box to align it with the text field, select the textbox and hover over it. Once you see a plus icon with arrows, move the textbox to the desired position. To edit the text, select the text box. Once you see the cursor and keypad, edit the text and then click elsewhere to enter. To change the text size, select A or A as required.\",\n",
      "      \"page_number\": 2\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Learn Acrobat - Request e-signatures_1.pdf\",\n",
      "      \"refined_text\": \"Open the PDF form in Acrobat or Acrobat Reader, and then choose All tools > Request E-signatures. Alternatively, you can select Sign from the top toolbar. The Request Signatures window is displayed. In the recipients field, add recipient email addresses in the order you want the document to be signed. The Mail and Message fields are just like the ones you use for sending an email and appear to your recipients in the same way. Change the default text in the Subject & Message area as appropriate.\",\n",
      "      \"page_number\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== challenge1b_final_output (2).json ===\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"input_documents\": [\n",
      "      \"Breakfast Ideas.pdf\",\n",
      "      \"Dinner Ideas - Mains_1.pdf\",\n",
      "      \"Dinner Ideas - Mains_2.pdf\",\n",
      "      \"Dinner Ideas - Mains_3.pdf\",\n",
      "      \"Dinner Ideas - Sides_1.pdf\",\n",
      "      \"Dinner Ideas - Sides_2.pdf\",\n",
      "      \"Dinner Ideas - Sides_3.pdf\",\n",
      "      \"Dinner Ideas - Sides_4.pdf\",\n",
      "      \"Lunch Ideas.pdf\"\n",
      "    ],\n",
      "    \"persona\": \"Food Contractor\",\n",
      "    \"job_to_be_done\": \"Prepare a vegetarian buffet-style dinner menu for a corporate gathering, including gluten-free items.\",\n",
      "    \"processing_timestamp\": \"2025-07-10T15:40:14.642503\"\n",
      "  },\n",
      "  \"extracted_sections\": [\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Sides_2.pdf\",\n",
      "      \"section_title\": \"Falafel\",\n",
      "      \"importance_rank\": 1,\n",
      "      \"page_number\": 7\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Sides_3.pdf\",\n",
      "      \"section_title\": \"Ratatouille\",\n",
      "      \"importance_rank\": 2,\n",
      "      \"page_number\": 8\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Sides_1.pdf\",\n",
      "      \"section_title\": \"Baba Ganoush\",\n",
      "      \"importance_rank\": 3,\n",
      "      \"page_number\": 4\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Lunch Ideas.pdf\",\n",
      "      \"section_title\": \"Veggie Sushi Rolls\",\n",
      "      \"importance_rank\": 4,\n",
      "      \"page_number\": 11\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Mains_2.pdf\",\n",
      "      \"section_title\": \"Vegetable Lasagna\",\n",
      "      \"importance_rank\": 5,\n",
      "      \"page_number\": 9\n",
      "    }\n",
      "  ],\n",
      "  \"subsection_analysis\": [\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Sides_2.pdf\",\n",
      "      \"refined_text\": \"Escalivada Ingredients: 2 eggplants, 2 bell peppers, 2 tomatoes, 1 small onion, 1/4 cup olive oil, 1 teaspoon salt. Instructions: Preheat oven to 400°F (200°C). Roast eggplants, bell peppers, tomatoes, and onion until tender. Peel and slice vegetables. Arrange on a plate and drizzle with olive oil. Sprinkle with salt and serve warm or at room temperature.\",\n",
      "      \"page_number\": 7\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Sides_2.pdf\",\n",
      "      \"refined_text\": \"Falafel Ingredients: 1 can chickpeas, 1 small onion, 2 cloves garlic, 1/4 cup parsley, 1 teaspoon cumin, 1 teaspoon coriander, 1 teaspoon salt, 1/4 cup flour, oil for frying. Instructions: Drain and rinse chickpeas. Blend chickpeas, diced onion, minced garlic, chopped parsley, cumin, coriander, and salt in a food processor. Add flour and mix until combined. Form mixture into balls and fry in hot oil until golden.\",\n",
      "      \"page_number\": 7\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Sides_1.pdf\",\n",
      "      \"refined_text\": \"Baba Ganoush Ingredients: 2 eggplants, 1/4 cup tahini, 1/4 cup lemon juice, 2 cloves garlic, 1/4 cup olive oil, 1 teaspoon salt. Instructions: Roast eggplants until soft, then peel and mash. Blend mashed eggplant, tahini, lemon juice, minced garlic, and salt in a food processor. Slowly add olive oil while blending until smooth. Serve with a drizzle of olive oil.\",\n",
      "      \"page_number\": 4\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Lunch Ideas.pdf\",\n",
      "      \"refined_text\": \"Veggie Sushi Rolls Ingredients: 1 cup cooked sushi rice, 1/2 cucumber (julienned), 1/2 avocado (sliced), 1/4 cup carrot (julienned), 2 sheets nori (seaweed), soy sauce for dipping. Instructions: Lay a sheet of nori on a bamboo sushi mat. Spread a thin layer of sushi rice over the nori, leaving a 1-inch border at the top. Arrange the cucumber, avocado, and carrot in a line along the bottom edge of the rice. Roll the nori tightly using the bamboo mat. Slice into bite-sized pieces and serve with soy sauce.\",\n",
      "      \"page_number\": 11\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"Dinner Ideas - Sides_3.pdf\",\n",
      "      \"refined_text\": \"Macaroni and Cheese Ingredients: 2 cups elbow macaroni, 2 cups milk, 2 tablespoons butter, 2 tablespoons flour, 2 cups shredded cheddar cheese, 1 teaspoon salt, 1/2 teaspoon pepper. Instructions: Cook macaroni according to package instructions, then drain. Melt butter in a saucepan, stir in flour to make a roux. Gradually add milk, stirring constantly until thickened. Add cheese, salt, and pepper, stir until melted. Combine cheese sauce with macaroni. Serve warm.\",\n",
      "      \"page_number\": 8\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== challenge1b_final_output.json ===\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"input_documents\": [\n",
      "      \"South of France - Cities.pdf\",\n",
      "      \"South of France - Cuisine.pdf\",\n",
      "      \"South of France - History.pdf\",\n",
      "      \"South of France - Restaurants and Hotels.pdf\",\n",
      "      \"South of France - Things to Do.pdf\",\n",
      "      \"South of France - Tips and Tricks.pdf\",\n",
      "      \"South of France - Traditions and Culture.pdf\"\n",
      "    ],\n",
      "    \"persona\": \"Travel Planner\",\n",
      "    \"job_to_be_done\": \"Plan a trip of 4 days for a group of 10 college friends.\",\n",
      "    \"processing_timestamp\": \"2025-07-10T15:31:22.632389\"\n",
      "  },\n",
      "  \"extracted_sections\": [\n",
      "    {\n",
      "      \"document\": \"South of France - Cities.pdf\",\n",
      "      \"section_title\": \"Comprehensive Guide to Major Cities in the South of France\",\n",
      "      \"importance_rank\": 1,\n",
      "      \"page_number\": 1\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Things to Do.pdf\",\n",
      "      \"section_title\": \"Coastal Adventures\",\n",
      "      \"importance_rank\": 2,\n",
      "      \"page_number\": 2\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Cuisine.pdf\",\n",
      "      \"section_title\": \"Culinary Experiences\",\n",
      "      \"importance_rank\": 3,\n",
      "      \"page_number\": 6\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Tips and Tricks.pdf\",\n",
      "      \"section_title\": \"General Packing Tips and Tricks\",\n",
      "      \"importance_rank\": 4,\n",
      "      \"page_number\": 2\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Things to Do.pdf\",\n",
      "      \"section_title\": \"Nightlife and Entertainment\",\n",
      "      \"importance_rank\": 5,\n",
      "      \"page_number\": 11\n",
      "    }\n",
      "  ],\n",
      "  \"subsection_analysis\": [\n",
      "    {\n",
      "      \"document\": \"South of France - Things to Do.pdf\",\n",
      "      \"refined_text\": \"The South of France is renowned for its beautiful coastline along the Mediterranean Sea. Here are some activities to enjoy by the sea: Beach Hopping: Nice - Visit the sandy shores and enjoy the vibrant Promenade des Anglais; Antibes - Relax on the pebbled beaches and explore the charming old town; Saint-Tropez - Experience the exclusive beach clubs and glamorous atmosphere; Marseille to Cassis - Explore the stunning limestone cliffs and hidden coves of Calanques National Park; Îles d'Hyères - Discover pristine beaches and excellent snorkeling opportunities on islands like Porquerolles and Port-Cros; Cannes - Enjoy the sandy beaches and luxury beach clubs along the Boulevard de la Croisette; Menton - Visit the serene beaches and beautiful gardens in this charming town near the Italian border.\",\n",
      "      \"page_number\": 2\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Cuisine.pdf\",\n",
      "      \"refined_text\": \"In addition to dining at top restaurants, there are several culinary experiences you should consider: Cooking Classes - Many towns and cities in the South of France offer cooking classes where you can learn to prepare traditional dishes like bouillabaisse, ratatouille, and tarte tropézienne. These classes are a great way to immerse yourself in the local culture and gain hands-on experience with regional recipes. Some classes even include a visit to a local market to shop for fresh ingredients. Wine Tours - The South of France is renowned for its wine regions, including Provence and Languedoc. Take a wine tour to visit vineyards, taste local wines, and learn about the winemaking process. Many wineries offer guided tours and tastings, giving you the opportunity to sample a variety of wines and discover new favorites.\",\n",
      "      \"page_number\": 6\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Things to Do.pdf\",\n",
      "      \"refined_text\": \"The South of France offers a vibrant nightlife scene, with options ranging from chic bars to lively nightclubs: Bars and Lounges - Monaco: Enjoy classic cocktails and live jazz at Le Bar Americain, located in the Hôtel de Paris; Nice: Try creative cocktails at Le Comptoir du Marché, a trendy bar in the old town; Cannes: Experience dining and entertainment at La Folie Douce, with live music, DJs, and performances; Marseille: Visit Le Trolleybus, a popular bar with multiple rooms and music styles; Saint-Tropez: Relax at Bar du Port, known for its chic atmosphere and waterfront views. Nightclubs - Saint-Tropez: Dance at the famous Les Caves du Roy, known for its glamorous atmosphere and celebrity clientele; Nice: Party at High Club on the Promenade des Anglais, featuring multiple dance floors and top DJs; Cannes: Enjoy the stylish setting and rooftop terrace at La Suite, offering stunning views of Cannes.\",\n",
      "      \"page_number\": 11\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Things to Do.pdf\",\n",
      "      \"refined_text\": \"Water Sports: Cannes, Nice, and Saint-Tropez - Try jet skiing or parasailing for a thrill; Toulon - Dive into the underwater world with scuba diving excursions to explore wrecks; Cerbère-Banyuls - Visit the marine reserve for an unforgettable diving experience; Mediterranean Coast - Charter a yacht or join a sailing tour to explore the coastline and nearby islands; Marseille - Go windsurfing or kitesurfing in the windy bays; Port Grimaud - Rent a paddleboard and explore the canals of this picturesque village; La Ciotat - Try snorkeling in the clear waters around the Île Verte.\",\n",
      "      \"page_number\": 2\n",
      "    },\n",
      "    {\n",
      "      \"document\": \"South of France - Tips and Tricks.pdf\",\n",
      "      \"refined_text\": \"General Packing Tips and Tricks: Layering - The weather can vary, so pack layers to stay comfortable in different temperatures; Versatile Clothing - Choose items that can be mixed and matched to create multiple outfits, helping you pack lighter; Packing Cubes - Use packing cubes to organize your clothes and maximize suitcase space; Roll Your Clothes - Rolling clothes saves space and reduces wrinkles; Travel-Sized Toiletries - Bring travel-sized toiletries to save space and comply with airline regulations; Reusable Bags - Pack a few reusable bags for laundry, shoes, or shopping; First Aid Kit - Include a small first aid kit with band-aids, antiseptic wipes, and any necessary medications; Copies of Important Documents - Make copies of your passport, travel insurance, and other important documents. Keep them separate from the originals.\",\n",
      "      \"page_number\": 2\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import glob, json, os\n",
    "\n",
    "# List all files in the current directory\n",
    "all_files = os.listdir(\".\")\n",
    "print(\"All files in the directory:\", all_files)\n",
    "\n",
    "# Filter for files that start with \"challenge1b_final_output\" and end with \".json\"\n",
    "output_files = [f for f in all_files if f.startswith('challenge1b_final_output') and f.endswith('.json')]\n",
    "\n",
    "# Sort the list of output files\n",
    "output_files.sort()\n",
    "\n",
    "print(\"\\nFound these final output files:\\n\", \"\\n\".join(output_files) or \"(none)\", \"\\n\")\n",
    "\n",
    "for fn in output_files:\n",
    "    print(f\"\\n=== {fn} ===\")\n",
    "    try:\n",
    "        with open(fn, encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            data = json.loads(text)\n",
    "            print(json.dumps(data, indent=2, ensure_ascii=False))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"⚠️ JSON Decode Error: {e}\")\n",
    "        print(\"Raw start of file:\\n\", text[:500], \"…\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ File not found: {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbfnIlNfwb3C",
    "outputId": "4d0a80f3-1893-4a7a-9dc0-cc75f3d2efa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All JSON files in working dir:\n",
      "\n",
      " • challenge1b_input (1).json\n",
      " • challenge1b_input (2).json\n",
      " • challenge1b_input.json\n",
      " • challenge1b_output (1).json\n",
      " • challenge1b_output (2).json\n",
      " • challenge1b_output.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"All JSON files in working dir:\\n\")\n",
    "for fn in sorted(os.listdir(\".\")):\n",
    "    if fn.endswith(\".json\"):\n",
    "        print(\" •\", fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B16ZieRikBCN"
   },
   "source": [
    "## Local Inference on GPU\n",
    "Model page: https://huggingface.co/google/flan-t5-base\n",
    "\n",
    "⚠️ If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/google/flan-t5-base)\n",
    "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) 🙏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1i5AfK2kBCU"
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
